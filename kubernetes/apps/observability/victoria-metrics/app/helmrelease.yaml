---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/refs/heads/main/ocirepository-source-v1beta2.json
apiVersion: source.toolkit.fluxcd.io/v1
kind: OCIRepository
metadata:
  name: victoria-metrics-k8s-stack
spec:
  interval: 2h
  layerSelector:
    mediaType: application/vnd.cncf.helm.chart.content.v1.tar+gzip
    operation: copy
  url: oci://ghcr.io/victoriametrics/helm-charts/victoria-metrics-k8s-stack
  ref:
    tag: 0.52.0
---
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: victoria-metrics
spec:
  chartRef:
    kind: OCIRepository
    name: victoria-metrics-k8s-stack
  interval: 15m
  maxHistory: 3
  install:
    crds: CreateReplace
    remediation:
      retries: -1
  upgrade:
    crds: CreateReplace
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    fullnameOverride: stack
    victoria-metrics-operator:
      env:
        - name: VM_VMALERTDEFAULT_CONFIGRELOADERCPU
          value: 0
        - name: VM_VMAGENTDEFAULT_CONFIGRELOADERCPU
          value: 0
        - name: VM_VMALERTMANAGER_CONFIGRELOADERCPU
          value: 0
      operator:
        disable_prometheus_converter: false # Ensure we keep enabled the converter to sync prom rules to VM rules
        enable_converter_ownership: true # Required to allow VM to remove VM rules it imports if a prometheus rule is deleted

    defaultDashboards:
      enabled: false

    defaultRules:
      rules:
        groups:
          etcd:
            create: false
          kubernetesSystemControllerManager:
            create: false
          kubernetesSystemScheduler:
            create: false

    vmsingle:
      spec:
        # -- Data retention period. Possible units character: h(ours), d(ays), w(eeks), y(ears), if no unit character specified - month. The minimum retention period is 24h. See these [docs](https://docs.victoriametrics.com/single-server-victoriametrics/#retention)
        retentionPeriod: "1y"
        replicaCount: 1
        extraArgs:
          maxLabelsPerTimeseries: "50"
        storage:
          accessModes:
            - ReadWriteOnce
          resources:
            requests:
              storage: 200Gi
        resources:
          limits:
            memory: 6Gi
          requests:
            cpu: 500m
            memory: 2Gi

    alertmanager:
      spec:
        externalURL: https://am.monosense.io
      useManagedConfig: true
      config:
        route:
          group_by: ["alertname", "job"]
          group_interval: 10m
          group_wait: 1m
          receiver: telegram
          repeat_interval: 12h
          routes:
            - receiver: "null"
              matchers:
                - alertname=InfoInhibitor
            - receiver: heartbeat
              group_interval: 15s
              group_wait: 0s
              repeat_interval: 5m
              matchers:
                - alertname=Watchdog
            - receiver: telegram
              matchers:
                - severity=~"warning|critical"
        inhibit_rules:
          - source_matchers:
              - severity = "critical"
            target_matchers:
              - severity = "warning"
            equal: ["alertname", "namespace"]
        receivers:
          - name: "null"
          - name: heartbeat
            webhook_configs:
              - url_secret:
                  name: &secret alertmanager-secret
                  key: ALERTMANAGER_HEARTBEAT_URL
          - name: telegram
            webhookConfigs:
              - url: http://alertmanager-telegram.observability.svc.cluster.local:8080/alerts

    vmalert:
      spec:
        # Skip vmalerts for vmlog rules
        selectAllByDefault: false
        ruleSelector:
          matchExpressions:
            - key: vmalert-logs.io/enabled
              operator: NotIn
              values: ["true"]
        ruleNamespaceSelector:
          matchExpressions:
            - key: somekey
              operator: NotIn
              values: ["never-used-value"]
        extraArgs:
          external.url: https://vm.monosense.io

    vmagent:
      spec:
        extraArgs:
          promscrape.maxScrapeSize: 50MiB
          promscrape.streamParse: "true"
          promscrape.dropOriginalLabels: "true"
        resources:
          limits:
            memory: 1Gi
          requests:
            cpu: 500m
            memory: 500Mi

    grafana:
      enabled: false

    prometheus-node-exporter:
      vmScrape:
        spec:
          endpoints:
            - port: metrics
              relabelConfigs:
                - source_labels:
                    - __meta_kubernetes_endpoint_node_name
                  target_label: node

    kubelet:
      vmScrape:
        spec:
          # drop high cardinality label and useless metrics for cadvisor and kubelet
          metricRelabelConfigs:
            # Drop less useful container CPU metrics.
            - sourceLabels: [__name__]
              action: drop
              regex: "container_cpu_(cfs_throttled_seconds_total|load_average_10s|system_seconds_total|user_seconds_total)"
            # Drop less useful / always zero container memory metrics.
            - sourceLabels: [__name__]
              action: drop
              regex: "container_memory_(failures_total|mapped_file|swap)"
            # Drop less useful container process metrics.
            - sourceLabels: [__name__]
              action: drop
              # regex: 'container_(file_descriptors|tasks_state|threads_max)'
              regex: "container_(tasks_state|threads_max)"
            # Drop less useful container filesystem metrics.
            - sourceLabels: [__name__]
              action: drop
              regex: "container_fs_(io_current|io_time_seconds_total|io_time_weighted_seconds_total|reads_merged_total|sector_reads_total|sector_writes_total|writes_merged_total)"
            # Drop less useful container blkio metrics.
            - sourceLabels: [__name__]
              action: drop
              regex: "container_blkio_device_usage_total"
            # Drop container spec metrics that overlap with kube-state-metrics.
            - sourceLabels: [__name__]
              action: drop
              regex: "container_spec.*"
            # Drop cgroup metrics with no pod.
            - sourceLabels: [id, pod]
              action: drop
              regex: ".+;"
            - action: drop
              sourceLabels: [__name__]
              regex: prober_probe_duration_seconds_bucket
            # Drop high-cardinality labels.
            - action: labeldrop
              regex: (uid|id|pod_uid|interface)
            - action: drop
              sourceLabels: [__name__]
              regex: (rest_client_request_duration_seconds_bucket|rest_client_request_duration_seconds_sum|rest_client_request_duration_seconds_count)

    kubeControllerManager:
      enabled: false

    kubeEtcd:
      enabled: false

    kubeScheduler:
      enabled: false

    kubeProxy:
      enabled: false

    additionalVictoriaMetricsMap:
      dockerhub-rules:
        create: true
        groups:
          - name: dockerhub
            rules:
              - alert: DockerhubRateLimitRisk
                annotations:
                  summary: Kubernetes cluster Dockerhub rate limit risk
                expr: count(time() - container_last_seen{image=~"(docker.io).*",container!=""} < 30) > 100
                labels:
                  severity: critical
      oom-rules:
        create: true
        groups:
          - name: oom
            rules:
              - alert: OomKilled
                annotations:
                  summary: Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.
                expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
                labels:
                  severity: critical
